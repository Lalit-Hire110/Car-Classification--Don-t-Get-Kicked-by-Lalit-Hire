{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U-Zog05LZRW"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "One of the biggest challenges of an auto dealership purchasing a used car at an auto auction is the risk of that the vehicle might have serious issues that prevent it from being sold to customers. The auto community calls these unfortunate purchases \"kicks\".\n",
    "\n",
    "Kicked cars often result when there are tampered odometers, mechanical issues the dealer is not able to address, issues with getting the vehicle title from the seller, or some other unforeseen problem. Kick cars can be very costly to dealers after transportation cost, throw-away repair work, and market losses in reselling the vehicle.\n",
    "\n",
    "In this project we will see the cars which has higher risk of being kick, which can help real value for dealership and provide best selection for the customers,\n",
    "\n",
    "We will take a look at real world data for 150,000 customers and use machine learning techniques to build the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiWDXMNHSs_h"
   },
   "source": [
    "## Installing and immporting all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiahRg3QBdaV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import opendatasets as od\n",
    "import os\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raV6Yd5jS8XL"
   },
   "source": [
    "## Downloading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMO6QGf-CEPZ"
   },
   "outputs": [],
   "source": [
    "# Correct syntax\n",
    "url = 'https://www.kaggle.com/competitions/DontGetKicked/data.csv'\n",
    "#df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtR3gTz7CMVT",
    "outputId": "a66654f5-00f8-4866-a83a-8a06ea8fb35b"
   },
   "outputs": [],
   "source": [
    "od.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "990du0NDCOnj",
    "outputId": "c0bec4e0-39cc-4af1-c3c2-41939c4e678b"
   },
   "outputs": [],
   "source": [
    "os.listdir('./DontGetKicked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QA33MoMIDHm4"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('DontGetKicked/training.csv')\n",
    "test_df = pd.read_csv('DontGetKicked/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSWGgos-TQZR"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFqrjFMhWWCF"
   },
   "source": [
    "We have the dataset downloaded and loaded in the dataframe. Let's check the data we have. We have train.csv which contains the training data and test.csv for testing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "id": "CTLVIn_MD3-p",
    "outputId": "3a624c7b-a71a-46b1-8bc2-d101eadfcc36"
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbUl8kS_D8Xj",
    "outputId": "c7dde2e6-07e7-4fa5-a714-3f59eb417e5a"
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "NdR9cWtqlJiJ",
    "outputId": "42ee1b68-2df4-446c-f324-03d39227e27a"
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "u9iSJVczEWc3",
    "outputId": "f3588be3-0b59-4400-923b-108519207a41"
   },
   "outputs": [],
   "source": [
    "a = train_df.IsBadBuy.value_counts()\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.barplot(x=['NO','Yes'],y=a)\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Is a Bad Buy\", fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWXI3RDPXgtH"
   },
   "source": [
    "**Insights**: In this dataset our target variable is `IsBadBuy`, by analysing the target variable we can see that there are 64K values stating its a good buy and 9K stating its a Bad buy.Hence our data is Imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "_KYV30cCzKXi",
    "outputId": "62118354-0e34-4450-cc9a-03d296b595d7"
   },
   "outputs": [],
   "source": [
    "b = train_df.Auction.value_counts()\n",
    "colors = ['cyan', 'lightblue','pink']\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Purchase in Auction',fontsize=18)\n",
    "plt.pie(b,colors=colors,\n",
    "        labels =['MANHEIM','OTHER','ADESA'],\n",
    "        autopct = '%1.1f%%',startangle=90,shadow=True,\n",
    "       radius = 1.2,explode = (0, 0.0005,0))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97i_oNfRlAsF"
   },
   "source": [
    "By seeing this chart we can tell that `Manheim` is the Auction place where maximum number of vehicles purchased in the auction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "YzDL1vicGC0w",
    "outputId": "13cd93c7-9597-4c6f-8819-a70eaa57a565"
   },
   "outputs": [],
   "source": [
    "age = pd.DataFrame(train_df.VehicleAge.value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=age.index,y='VehicleAge',data=age)\n",
    "plt.ylabel('count',fontsize=18)\n",
    "plt.title('Vehicle Age',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpMbzeZulccr"
   },
   "source": [
    "Insights: We can see that people prefer to buy the vehicle age of 3 & 4 regarding the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "9TVquxHKoRjr",
    "outputId": "71d0125e-6c1b-4f80-fdef-44e1dca56842"
   },
   "outputs": [],
   "source": [
    "make = pd.DataFrame(train_df.Make.value_counts())\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=make.index,y='Make',data=make)\n",
    "plt.ylabel('count',fontsize=18)\n",
    "plt.xticks(rotation=75)\n",
    "plt.title('Make',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7nPjWBWmO_A"
   },
   "source": [
    "Insights: Chevrolet is the company which people have purchased the vehicle a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "tAeWwLragxt_",
    "outputId": "17e24666-9581-47de-e32a-91d561ca506c"
   },
   "outputs": [],
   "source": [
    "px.histogram(train_df, x=\"VehicleAge\", color='IsBadBuy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuqoz4Hhmp38"
   },
   "source": [
    "Insights: Distibutions of vehicle age with the purchase was a good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "RNDUkg7cZiWg",
    "outputId": "4331e9e7-351d-4d57-dcf1-00c0efa6ff94"
   },
   "outputs": [],
   "source": [
    "px.histogram(train_df, x= \"Make\", color='IsBadBuy',width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n1fkXPcnb9_"
   },
   "source": [
    "Insights: Chevrolet and Dodge are the companies which are in high demand of the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "oNND6GPnqrK4",
    "outputId": "18cfb7fb-1ec5-4056-e826-f3e46c7b6600"
   },
   "outputs": [],
   "source": [
    "px.histogram(train_df, x= \"Nationality\", color='IsBadBuy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlIy5-tOntD_"
   },
   "source": [
    "Insights: Seems like vehicle of America has been purchased a lot and it has the higher demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "zsajqCdSFZXE",
    "outputId": "ae26d0a9-605b-43c5-a741-6a8a07252c21"
   },
   "outputs": [],
   "source": [
    "px.histogram(train_df, x= \"Size\", color='IsBadBuy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COck5NyIoP4J"
   },
   "source": [
    "Insights: Majority of the People prefer to purchase the Medium size vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "ATb1CzKdqbFo",
    "outputId": "6191f4cf-da4b-4322-85b9-cd36a38b55b1"
   },
   "outputs": [],
   "source": [
    "px.histogram(train_df,x='VNST',width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVWsaXQyqyAX"
   },
   "source": [
    "Insights: Texas is the state from where the vehicle purchase is more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "W3Hv05BkG1Zd",
    "outputId": "e079177e-5928-45b9-c58f-a3394d3fc020"
   },
   "outputs": [],
   "source": [
    "px.histogram(train_df,x='WheelType',y='IsBadBuy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaH9Zx21rKvs"
   },
   "source": [
    "Insights: Majority of the vehicle purchased Wheel Type as Alloy , this might be because the Wheel type Special costs more price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "mO1IF0lybUPO",
    "outputId": "14adfda7-0499-4be6-f5e9-1e5605484deb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = train_df.corr(numeric_only=True)\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask_matrix = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(corr, \n",
    "            mask=mask_matrix, \n",
    "            cmap='crest', \n",
    "            annot=True, \n",
    "            fmt=\".2f\", \n",
    "            linewidths=0.5, \n",
    "            square=True, \n",
    "            cbar_kws={\"shrink\": 0.75})\n",
    "\n",
    "plt.title(\"Correlation Heatmap\", fontsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6SezhvCokTM"
   },
   "source": [
    "Insights: Here we can clearly see that the MMRA price columns are very strongly correlated with each other which might affect the accuracy of what we are trying to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "OjFaoLu3g4T9",
    "outputId": "f159b28c-8ffb-445b-b568-0eae5aeb97ca"
   },
   "outputs": [],
   "source": [
    "px.scatter(train_df, x=\"MMRAcquisitionAuctionAveragePrice\", y=\"MMRAcquisitionRetailAveragePrice\",color=\"IsBadBuy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EDL4Z6doy9N"
   },
   "source": [
    "Insights : It is clearly obvious that there is a strong positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "wriXpe-g6rWo",
    "outputId": "10a33c61-be0f-4ede-eb79-1a293e3f22ea"
   },
   "outputs": [],
   "source": [
    "px.scatter(train_df, x = \"MMRCurrentAuctionAveragePrice\",y = \"MMRCurrentAuctionCleanPrice\", color='IsBadBuy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhS6mni6paP8"
   },
   "source": [
    "Insights: The above graph is evident there is a positive correlation here and after 20K mark the vehicle seems to fall in Bad Buy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "StJ_BHhHD_lw",
    "outputId": "946b925a-9732-46d6-ab2d-e8d1a1ab4002"
   },
   "outputs": [],
   "source": [
    "px.scatter(train_df, x='MMRCurrentRetailAveragePrice', y='MMRCurrentRetailCleanPrice', color='IsBadBuy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM1SXmODo-AS"
   },
   "source": [
    "Insights: The above graph is evident there is a positive correlation here and after 20K mark the vehicle seems to fall in Bad Buy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcWjlXDISHSj",
    "outputId": "0337514a-4a22-4552-8836-4af0eebdc336"
   },
   "outputs": [],
   "source": [
    "# Download competition files\n",
    "!kaggle competitions download -c DontGetKicked\n",
    "\n",
    "# Unzip the downloaded zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"DontGetKicked.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"DontGetKicked\")\n",
    "\n",
    "# text_file = open('/content/DontGetKicked/Carvana_Data_Dictionary.txt')\n",
    "# content = text_file.read()\n",
    "# print(content)\n",
    "# text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "for root, dirs, files in os.walk(\".\", topdown=True):\n",
    "    for name in files:\n",
    "        if name.endswith(\".txt\"):\n",
    "            print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxd3m9Bmp8rB"
   },
   "source": [
    "Let's check the null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DontGetKicked/Carvana_Data_Dictionary.txt\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tAA-FsGVmNU",
    "outputId": "2e473cbe-421f-45d3-c034-5135475c3656"
   },
   "outputs": [],
   "source": [
    "train_df.isna().sum()*100/len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzog67y1qESN"
   },
   "source": [
    "We can see that there are lot of NaN values present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuIq5Hgga4i9",
    "outputId": "04d26ab1-4428-452c-a80c-91a37607546c"
   },
   "outputs": [],
   "source": [
    "train_df.IsOnlineSale.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s96XJJDLTuJ-"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39c6Vzowg62C"
   },
   "outputs": [],
   "source": [
    "train_df['Transmission'] = train_df['Transmission'].replace({'manual':'MANUAL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDH4uuck2AW5",
    "outputId": "e8e9fd8e-03fe-42a4-f56a-2509bc92b9d5"
   },
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KSYHAVdrnvZ"
   },
   "source": [
    "Inshights: We have approx 90% of nun values in `PrimeUnit` & `Aucguart` so its better to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m5femL1ED27_"
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Trim','Model','RefId','VehYear','WheelTypeID','VNZIP1','PRIMEUNIT','AUCGUART','PurchDate'], axis=1, inplace=True)\n",
    "test_df.drop(['Trim','Model','RefId','VehYear','WheelTypeID','VNZIP1','PRIMEUNIT','AUCGUART','PurchDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI4C4N9Yr7WZ"
   },
   "source": [
    "Removing Unecessary columns which may not impact our model and our model can learn better without this columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "kEN9a8Y7FQgE",
    "outputId": "ca0eb259-4ba4-419a-ebc3-c1f88b301573"
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5zqWSmwlnv5"
   },
   "outputs": [],
   "source": [
    "train_targets = train_df['IsBadBuy']\n",
    "train_df.drop('IsBadBuy',axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxPYjPVnsOWO"
   },
   "source": [
    "Splitting the Dependent variable and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "Ifg68WxNbbVB",
    "outputId": "dad7d21a-693c-43d6-8e77-116d455fe869"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdHD3t6Hsgeq"
   },
   "source": [
    "### Conclusions\n",
    "\n",
    "\n",
    "1. We can drop **`Model`** & **`Trim`** as they have alot of categories and model wont be able to learn all of them.\n",
    "\n",
    "\n",
    "2. Note: **`WheelType`** and **`WheelTypeID`** are one and the same. One of them is containing numeric categories and other as string. Its better we drop **`WheelTypeID`** as the other column has type of metal used for making the wheel which might help us understand the importance of a particular metal used in making the wheel\n",
    "\n",
    "3.  **`VehYear`** might not play a crucial role as we have  **`VehicleAge`** as a column. The  **`PurchDate`** varies and similarly  **`VehYear`** varies.The only thing that matters is how much old the vehicle is at the time of resale. Thus `drop` **`VehYear`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLIApM9TT19f"
   },
   "source": [
    "# Encoding & Imputing Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icGIHUaFtFcq"
   },
   "source": [
    "It is always a good practice to indentify the numerical and catagorical columns so that it becomes easier to work on them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_5DkwLomN3i"
   },
   "outputs": [],
   "source": [
    "num_cols = train_df.select_dtypes(exclude='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-AfoYP0tZ2O"
   },
   "source": [
    "We all know that machine learning models cannot work with missing data therefore we will need to fill these missing values and this process is called imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfFH7WjLRPKz"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeS1S_SARegA"
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQtldmVxtnVo"
   },
   "source": [
    "Implementing simple imputer so that missing values can be filled with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzCSJcHpSgtS"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Select numeric columns\n",
    "num_cols = train_df.select_dtypes(include='number').columns\n",
    "\n",
    "# Initialize imputer\n",
    "imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent', etc.\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "imputer.fit(train_df[num_cols])\n",
    "\n",
    "# Transform the data and update the DataFrame\n",
    "train_df[num_cols] = imputer.transform(train_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQPR0JGITfPA"
   },
   "outputs": [],
   "source": [
    "imputer.fit(test_df[num_cols])\n",
    "test_df[num_cols] = imputer.transform(test_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aE52ddeIVSi4",
    "outputId": "716b0c68-c262-421a-85cd-f6f7c5ccddd2"
   },
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gD006gubtvXE"
   },
   "source": [
    "Simple Imputer doesnot work for the categorical values or objects so that we are applying different stratergy for filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjoWLZAkz8dp"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.apply(lambda x: x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVnS5dtw0CSQ"
   },
   "outputs": [],
   "source": [
    "test_df = test_df.apply(lambda x: x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhqKIRAP0I9Z",
    "outputId": "7e4d4cd9-0025-4f36-c479-487b5f56209d"
   },
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKSsJw44de4M"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-VT8cJsuN5K"
   },
   "source": [
    "Selecting some specific columns so that label encoding can be applied because label encoding takes the labels as `rank`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6D7NFeGhGvp"
   },
   "outputs": [],
   "source": [
    "train_df['Auction']= label_encoder.fit_transform(train_df[\"Auction\"])\n",
    "train_df['Transmission']= label_encoder.fit_transform(train_df['Transmission'])\n",
    "train_df['WheelType']= label_encoder.fit_transform(train_df['WheelType'])\n",
    "train_df['Nationality']= label_encoder.fit_transform(train_df['Nationality'])\n",
    "train_df['TopThreeAmericanName']= label_encoder.fit_transform(train_df['TopThreeAmericanName'])\n",
    "\n",
    "test_df['Auction']= label_encoder.fit_transform(test_df[\"Auction\"])\n",
    "test_df['Transmission']= label_encoder.fit_transform(test_df['Transmission'])\n",
    "test_df['WheelType']= label_encoder.fit_transform(test_df['WheelType'])\n",
    "test_df['Nationality']= label_encoder.fit_transform(test_df['Nationality'])\n",
    "test_df['TopThreeAmericanName']= label_encoder.fit_transform(test_df['TopThreeAmericanName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "4rmwdH54hrRt",
    "outputId": "82474206-506e-4cd0-9619-c8b9c79e9a56"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njbdknd6lByX"
   },
   "outputs": [],
   "source": [
    "category_col = train_df.select_dtypes(include = 'object').columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ggu8nCL7ukWE"
   },
   "source": [
    "**Encoding Categorical Data:**\n",
    "\n",
    "Since machine learning models can only be trained with numeric data, we need to convert categorical data to numbers. A very common technique is to use one-hot encoding for categorical columns.\n",
    "\n",
    "<img src=\"https://i.imgur.com/n8GuiOO.png\" width=\"640\">\n",
    "\n",
    "One hot encoding involves adding a new binary (0/1) column for each unique category of a categorical column.\n",
    "\n",
    "\n",
    "We will use `OneHotEncoder` from `sklearn.preprocessing` to achive this goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ERvc-dSUB1S"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maMGhDsiUtdi",
    "outputId": "8402a231-4996-4e31-bbb8-d5bb5819e50f"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Update for latest sklearn version\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit only on training data\n",
    "encoder.fit(train_df[category_col])\n",
    "\n",
    "# Transform both datasets\n",
    "train_encoded = encoder.transform(train_df[category_col])\n",
    "test_encoded = encoder.transform(test_df[category_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjSLBKXslqLa",
    "outputId": "3d705b7c-b446-423e-f0e0-7b0f28886fec"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define and fit encoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoder.fit(train_df[category_col])\n",
    "\n",
    "# Transform data\n",
    "train_encoded = encoder.transform(train_df[category_col])\n",
    "\n",
    "# Get new column names\n",
    "encoded_cols = list(encoder.get_feature_names_out(category_col))\n",
    "\n",
    "# Create DataFrame with encoded columns\n",
    "import pandas as pd\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=encoded_cols)\n",
    "\n",
    "# Optional: Reset index if needed to merge\n",
    "train_encoded_df.index = train_df.index\n",
    "\n",
    "# Combine with original DataFrame (dropping old categorical columns)\n",
    "train_df_final = pd.concat([train_df.drop(columns=category_col), train_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouS1wunUuxAy"
   },
   "source": [
    "After fitting the categorical columns to the `OneHotEncoder` object, the encoder creates a list of new columns from all the categories in the columns and we can access them using `get_feature_names_out`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5pS2zpeu8T_"
   },
   "source": [
    "Now we will use these encoded columns names to transform the columns into encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVYubBmmmALv",
    "outputId": "5a73f0d9-4bc3-4ae6-98dc-1ce768ce6ef9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Transform categorical columns\n",
    "train_encoded = encoder.transform(train_df[category_col])\n",
    "test_encoded = encoder.transform(test_df[category_col])\n",
    "\n",
    "# Create DataFrames from encoded arrays\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=encoded_cols, index=train_df.index)\n",
    "test_encoded_df = pd.DataFrame(test_encoded, columns=encoded_cols, index=test_df.index)\n",
    "\n",
    "# Drop original categorical columns from the original dataframes\n",
    "train_df = train_df.drop(columns=category_col)\n",
    "test_df = test_df.drop(columns=category_col)\n",
    "\n",
    "# Concatenate encoded columns\n",
    "train_df = pd.concat([train_df, train_encoded_df], axis=1)\n",
    "test_df = pd.concat([test_df, test_encoded_df], axis=1)\n",
    "\n",
    "# Optional (to defragment memory)\n",
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "l0zsm_7DmWD6",
    "outputId": "a372e787-61b1-4bff-cb95-86134e4b48f6"
   },
   "outputs": [],
   "source": [
    "train_df[encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMYkb8ffUCf0"
   },
   "source": [
    "# Scaling Down the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PatYZEPMxh0",
    "outputId": "a87f5efe-344b-4bc3-8ba2-f8d5ff80bac3"
   },
   "outputs": [],
   "source": [
    "train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f82OzH5vY_n"
   },
   "source": [
    "Another good practice is to scale numeric features to a small range of values e.g. (0,1) or (−1,1). Scaling numeric features ensures that no particular feature has a disproportionate impact on the model's loss. Optimization algorithms also work better in practice with smaller numbers.\n",
    "\n",
    "We will use `MinMaxScaler` from `sklearn.preprocessing` to scale numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ot35XFk2YKZq"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTcyeN-AYW4x",
    "outputId": "a4ca4e9d-ab89-4b95-f83a-5f071db2ef6d"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8YF9xTYYhEK"
   },
   "outputs": [],
   "source": [
    "train_df[num_cols] = scaler.transform(train_df[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "U5QhayxAY5wE",
    "outputId": "84cc1976-1852-4397-e3eb-430121cfa736"
   },
   "outputs": [],
   "source": [
    "train_df[num_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zty_VioN2pLu"
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['Make', 'SubModel', 'Color', 'Size', 'VNST']\n",
    "\n",
    "missing_cols_train = [col for col in cols_to_drop if col not in train_df.columns]\n",
    "missing_cols_test = [col for col in cols_to_drop if col not in test_df.columns]\n",
    "\n",
    "print(\"Missing in train_df:\", missing_cols_train)\n",
    "print(\"Missing in test_df:\", missing_cols_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8DGIeWCvlzt"
   },
   "source": [
    "As we applied one hot encoding to the above columns lets drop these columns from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwwHORGYUcqE"
   },
   "source": [
    "# Training , Validation and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLYRZ3wpv9sH"
   },
   "source": [
    "**Training, Validation and Test Sets:**\n",
    "\n",
    "While building real-world machine learning models, it is quite common to split the dataset into three parts:\n",
    "\n",
    "1. **Training set** - used to train the model, i.e., compute the loss and adjust the model's weights using an optimization technique.\n",
    "\n",
    "\n",
    "2. **Validation set** - used to evaluate the model during training, tune model hyperparameters (optimization technique, regularization etc.), and pick the best version of the model. Picking a good validation set is essential for training models that generalize well.\n",
    "\n",
    "\n",
    "3. **Test set** - used to compare different models or approaches and report the model's final accuracy. For many datasets, test sets are provided separately. The test set should reflect the kind of data the model will encounter in the real-world, as closely as feasible.\n",
    "\n",
    "As a general rule of thumb you can use around 60% of the data for the training set, 20% for the validation set and 20% for the test set. If a separate test set is already provided, you can use a 75%-25% training-validation split.\n",
    "\n",
    "\n",
    "When rows in the dataset have no inherent order, it's common practice to pick random subsets of rows for creating test and validation sets. This can be done using the `train_test_split` utility from `scikit-learn`. Learn more about it here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1qHdwfjdObA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHriwWeddV_4"
   },
   "outputs": [],
   "source": [
    "inputs, val_inputs, train_targets, val_targets = train_test_split(train_df,train_targets, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPsaG1qyUugH"
   },
   "source": [
    "# Dumb Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8BB1oqbwD96"
   },
   "source": [
    "It's always a good idea to build a baseline or a dumb model first before training a machine learning model to actually have the baseline, which we need to perform better from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVWejKg4dqZC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77NUJp1cwdQH"
   },
   "source": [
    "We will use the `accuracy_score` from `sklearn.metrics` library to test the accuracy of models by computing the percentage of matching values between the predictions and actual targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tNazaqGxzre",
    "outputId": "647e8e1a-6fd5-43ca-ed0d-3cf21253a1cf"
   },
   "outputs": [],
   "source": [
    "dum_model_outs = np.zeros(len(inputs))\n",
    "accuracy_score(dum_model_outs,train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76V0Vuosw_pC"
   },
   "source": [
    "Our Dum Model saying 'No' has the accuracy of 87%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlS3W114U2aR"
   },
   "source": [
    "# Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eJkgOAzxL8z"
   },
   "source": [
    "We wiil make our first model which is going to be `LogisticRegression` model.\n",
    "We will use `LogisticRegression` from `sklearn.linear_model` to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pykiz-M2zIFD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAbDJhSLzqNv",
    "outputId": "d34e7b9c-44d4-4cad-8e0e-646ae3f91920"
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state = 42,solver='liblinear',class_weight={0: 1, 1:1.6})\n",
    "lr_model.fit(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ1Ty_cOxgNh"
   },
   "source": [
    "We have made the lr_model object and have fitted the training inputs to the model.\n",
    "Next we will get the predictions from the model and check the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lzpcn1am3IAf",
    "outputId": "60f6fc5c-4788-4945-e246-69b970b70040"
   },
   "outputs": [],
   "source": [
    "lr_model.score(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XV0h5pOY3RGY",
    "outputId": "2bdbb9ce-6027-4ca0-8c7b-058c1d15ce56"
   },
   "outputs": [],
   "source": [
    "lr_model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_y7FltEVv7R"
   },
   "outputs": [],
   "source": [
    "train_preds = lr_model.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IofER3zyx-rE"
   },
   "source": [
    "**Confusion Matrix:**\n",
    "\n",
    "A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.\n",
    "\n",
    "For a binary classification problem, we would have a 2 x 2 matrix as shown below with 4 values:\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/04/Basic-Confusion-matrix.png)\n",
    "\n",
    "- The target variable has two values: Positive or Negative\n",
    "- The columns represent the actual values of the target variable\n",
    "- The rows represent the predicted values of the target variable\n",
    "\n",
    "\n",
    "Here TP and TN means that the the predicted value matches the actual value, FN means that model predicted **False** but the actual value was **True** and FP means that the model predicted **True** but the actual value was **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ3bWhcJV5mE",
    "outputId": "44c71a9b-a058-440a-c69f-c9998b1cd085"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(train_targets, train_preds, normalize = 'pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1kvdDY8yhC4"
   },
   "source": [
    "In the above matrix we can see that the **TP** and **TN** have a percentage of 88% and 45% repectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iqaz2YHKVDGD",
    "outputId": "6bcdd58d-619b-435c-9e1f-7dfe18b2a22c"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(train_targets, train_preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uzjem6eZVjTc"
   },
   "outputs": [],
   "source": [
    "val_preds = lr_model.predict(val_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9Rq4c1sVxLy",
    "outputId": "5189e96e-c589-439a-b593-6298fee7022c"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(val_targets, val_preds, normalize = 'pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w44iM114yWvT"
   },
   "source": [
    "In the above matrix we can see that the **TP** and **TN** have a percentage of 88% and 41% repectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOckrYTaHMxa"
   },
   "outputs": [],
   "source": [
    "preds=lr_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZKsiEMCFSXo"
   },
   "source": [
    "# Model 2: KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3SsXzHLy5bz"
   },
   "source": [
    "We will create KNN classifier model.\n",
    "\n",
    "We will use `KNeighborsClassifier` from `sklearn.neighbors` to build the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2Vc1HHSLRUI"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(algorithm='auto',leaf_size=30,metric='minkowski',n_neighbors=11,weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xAdIzl-LRPX",
    "outputId": "fcd34077-33e5-4d0a-cf11-1eadfb150a81"
   },
   "outputs": [],
   "source": [
    "KNN.fit(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx9K4aluNbRR",
    "outputId": "89b36397-1816-412d-f288-061a64809ee9"
   },
   "outputs": [],
   "source": [
    "KNN.score(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46Yybu5SP1Iy",
    "outputId": "09f9b81c-dfdb-4fd9-e432-ecdda01d6025"
   },
   "outputs": [],
   "source": [
    "KNN.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCfP4Ll9zdxD"
   },
   "source": [
    "\n",
    "It seems we are getting the score of 87 in the validation set but `KNeighborsClassifier` takes some time to give the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_QpMutZZxf1"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'RefId': test_df['RefId'],  \n",
    "    'IsBadBuy': preds\n",
    "})\n",
    "\n",
    "preds=KNN.predict(test_df)\n",
    "submission_df['IsBadBuy']=preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS65cD3iF-Or"
   },
   "source": [
    "# Model 3: Decission Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vryd6_uWz7y5"
   },
   "source": [
    "Next We will create our 'Descision Tree' model.\n",
    "\n",
    "We will use `DecisionTreeClassifier` from `sklearn.tree` to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNNWUf8iGA3R"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ox2B2P4GzHS",
    "outputId": "8fd154ea-0f97-4243-8fda-e2125845949b"
   },
   "outputs": [],
   "source": [
    "model.fit(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58dfvXHIG6WU"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1eC7g5CjHMQK"
   },
   "outputs": [],
   "source": [
    "train_preds = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GjB3JuKHR0C",
    "outputId": "8964166b-1301-470f-a880-a6f68448b80b"
   },
   "outputs": [],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbGmR99CHXnd",
    "outputId": "c1b6a0b8-f47e-4c47-a498-a417c2a218ad"
   },
   "outputs": [],
   "source": [
    "pd.value_counts(train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sPVp5sFHdRQ",
    "outputId": "ef23dd6e-b198-4dcf-c232-e012be56e617"
   },
   "outputs": [],
   "source": [
    "train_probs = model.predict_proba(inputs)\n",
    "train_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vO7CwvgHnPn",
    "outputId": "5a7c703e-ad0d-4c67-eb70-58a0717bff65"
   },
   "outputs": [],
   "source": [
    "accuracy_score(train_targets, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2iBX4WSHxAd",
    "outputId": "8a885a9c-7cc5-427f-e0fe-e5fdc3257d69"
   },
   "outputs": [],
   "source": [
    "model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ4wheNM0Gz5"
   },
   "source": [
    "It seems we are getting the accuracy of 79% in the validation set lets apply some hyperparameter here to increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6r9eluEH8Pj",
    "outputId": "5718fceb-9e57-4a75-cbbe-1d5d8bbe4085"
   },
   "outputs": [],
   "source": [
    "val_targets.value_counts() / len(val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "EpbrolzuIF9K",
    "outputId": "37dc2f22-22db-4a92-c95c-5124cf048a06"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree, export_text\n",
    "plt.figure(figsize=(80,20))\n",
    "plot_tree(model, feature_names=inputs.columns, max_depth=3, filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urSl8C1lIQW7",
    "outputId": "2409a6dc-e055-430d-e8c2-b69cd8598aba"
   },
   "outputs": [],
   "source": [
    "model.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3x2AD1TInog"
   },
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    'feature': inputs.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "rLOTIlY7IyAX",
    "outputId": "1b9aafa8-514e-44af-90d6-4837d3d803a5"
   },
   "outputs": [],
   "source": [
    "plt.title('Feature Importance')\n",
    "sns.barplot(data=importance_df.head(10), x='importance', y='feature');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmFpSoPh0kpX"
   },
   "source": [
    "Importance of the feature in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRspHDcxI8qP"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crds4jIA0uPj"
   },
   "source": [
    "applying different values of max_depth of the tree to increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk6i0TPCJB6d",
    "outputId": "a0525e37-828f-4910-95ea-ab13b6752ee8"
   },
   "outputs": [],
   "source": [
    "model.fit(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_uvpFBRJFQT",
    "outputId": "944f9f96-b6f8-4778-863f-9631b0234f8f"
   },
   "outputs": [],
   "source": [
    "model.score(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WMNRqNeJKGe",
    "outputId": "08e9ee0e-e697-49d1-9731-d80d61e09bce"
   },
   "outputs": [],
   "source": [
    "model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vX3A2yag04ps"
   },
   "source": [
    "Now we can see that just by increasing the max depth of the tree we are getting the accuracy of 88% which is far better than 79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb5HfoKfJZy8"
   },
   "outputs": [],
   "source": [
    "def max_depth_error(md):\n",
    "    model = DecisionTreeClassifier(max_depth=md, random_state=42)\n",
    "    model.fit(inputs, train_targets)\n",
    "    train_acc = 1 - model.score(inputs, train_targets)\n",
    "    val_acc = 1 - model.score(val_inputs, val_targets)\n",
    "    return {'Max Depth': md, 'Training Error': train_acc, 'Validation Error': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ7DisKpfqLt"
   },
   "outputs": [],
   "source": [
    "errors_df = pd.DataFrame([max_depth_error(md) for md in range(1, 21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "46yaRczafoOq",
    "outputId": "7bd5272e-c133-4d68-8518-a00c5ea1502d"
   },
   "outputs": [],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "PXPOeLmuKgcA",
    "outputId": "a348a6c8-7c1d-43c0-b56a-bcc3331709cd"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(errors_df['Max Depth'], errors_df['Training Error'])\n",
    "plt.plot(errors_df['Max Depth'], errors_df['Validation Error'])\n",
    "plt.title('Training vs. Validation Error')\n",
    "plt.xticks(range(0,21, 2))\n",
    "plt.xlabel('Max. Depth')\n",
    "plt.ylabel('Prediction Error (1 - Accuracy)')\n",
    "plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6l281ce1V5R"
   },
   "source": [
    "Applying different hyperparameter values to tune the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANlCQvl2KzFp",
    "outputId": "8dffda24-1a7b-489c-fb8e-66a4bcf5c640"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=4,max_leaf_nodes=50,random_state=42).fit(inputs, train_targets)\n",
    "model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRdoJ96V1grb"
   },
   "source": [
    "Hence we got the accuracy of 88% in Decission tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ui5D5IoSKZ-j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBg3me-LMYhl"
   },
   "source": [
    "# Model 4: RandomForest Calssifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96hAxt1k2NBb"
   },
   "source": [
    "Next we will make our random forest classifier model and we will use `RandomForestClassifier` from `sklearn.ensemble`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YI_GjIeMMGq"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3E5RKN2fMUf0"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opQLtPECMfwP",
    "outputId": "444a6ede-d6dc-405d-8328-1e353023ac00"
   },
   "outputs": [],
   "source": [
    "model.fit(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82Ytp-ayMlVp",
    "outputId": "8a50c56a-b230-4293-b132-270ff5b5242d"
   },
   "outputs": [],
   "source": [
    "model.score(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1QK8ZzGMoNP",
    "outputId": "e1364e46-6f8e-4fbd-82a9-81ae04c76aaf"
   },
   "outputs": [],
   "source": [
    "model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj0A94VnM2cL",
    "outputId": "c65b407f-01af-4aaf-cd3c-78a56eeb9c8e"
   },
   "outputs": [],
   "source": [
    "train_probs = model.predict_proba(inputs)\n",
    "train_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show all columns in test_df\n",
    "# print(\"Columns in test_df:\")\n",
    "# print(test_df.columns.tolist())\n",
    "\n",
    "# # Preview first few rows\n",
    "# print(\"\\nFirst few rows:\")\n",
    "# print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0KS7aeeLnja"
   },
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1\n",
    "preds = model.predict_proba(test_df)[:, 1]\n",
    "\n",
    "# Create a submission DataFrame with auto-generated IDs\n",
    "submission_df = pd.DataFrame({\n",
    "    'RefId': range(len(test_df)),   # Auto-generated RefId: 0, 1, 2, ...\n",
    "    'IsBadBuy': preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv('rf_Submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IunmWAvKM3t6"
   },
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    'feature': inputs.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "JU6oksHh7M94",
    "outputId": "4895b6ac-b186-490a-d738-19c45c0ba0fa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title('Feature Importance')\n",
    "sns.barplot(data=importance_df.head(10),palette='husl',x='importance', y='feature');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2ldtqdpNaQg"
   },
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1, **params).fit(inputs, train_targets)\n",
    "    return model.score(inputs, train_targets), model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZHuonT3Obaj",
    "outputId": "62aaef37-18d7-4f25-b908-c407d3336d3b"
   },
   "outputs": [],
   "source": [
    "test_params(max_depth=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXd9ltgEO5CS",
    "outputId": "02b26acd-5d63-466c-f3af-0050c254b8b3"
   },
   "outputs": [],
   "source": [
    "test_params(max_leaf_nodes=2**12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeMuXJJtO-W7",
    "outputId": "31ea183e-2070-4d67-92ce-118a214a01b9"
   },
   "outputs": [],
   "source": [
    "test_params(max_features='log2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6hLXlgBcVW4"
   },
   "source": [
    "# Traing best Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RbheNti2GId"
   },
   "source": [
    "Since we had the highest accuracy with random forest so let's tune our randomm forest model and since it is a recursive process let's create a function to test our hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJF2XgG8PjoI"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1,\n",
    "                               random_state=42,\n",
    "                               n_estimators=300,\n",
    "                               max_features='log2',\n",
    "                               max_depth=40,\n",
    "                               class_weight={0: 1, 1: 1.6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrkrIE1zQPUe",
    "outputId": "5074fbce-761a-4934-822d-c7abc7041389"
   },
   "outputs": [],
   "source": [
    "model.fit(inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMprKOaoQTPi",
    "outputId": "4867f5dc-a90d-45e1-ef2e-526c880c18ea"
   },
   "outputs": [],
   "source": [
    "model.score(inputs, train_targets), model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCbxCwZLM3BG"
   },
   "outputs": [],
   "source": [
    "preds=model.predict_proba(test_df)\n",
    "submission_df['IsBadBuy']=preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Show the first few prediction results\n",
    "print(\"Prediction Results (Top 10):\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Step 4: Save to CSV\n",
    "submission_df.to_csv('rf_Submissions.csv', index=False)\n",
    "print(\"\\nSaved to 'rf_Submissions.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTTDVNjoRGy4"
   },
   "source": [
    "# **Summary**\n",
    "\n",
    "We downloaded , explored , performed EDA(Exploratory Data Analysis), cleaned the data and trained few models to automate the process of identifying that the car bought at auction is a good purchase or bad purchase.\n",
    "\n",
    "- Training data & test data had approximately 73K rows and 34 columns.\n",
    "- Prepared the dataset and removed the data which had more categories or which had high correlations\n",
    "- Imputed the missing values in both categorical columns and numeric columns.\n",
    "- Encoded the categorical columns with Label encoding & One hot encoding and scaled the numerical values using MinMaxScaler.\n",
    "- Then split the data into train data and validation data and trained the dumb model to get the baseline for our models.\n",
    "- Dataset was Imbalance , its important to balance the dataset first we applied `class_weights' parameter for balancing the data.\n",
    "- Trained four models:\n",
    "`LogisticRegression`,`KNNClassifier` `DecissionTree` and `RandomForest`.\n",
    "Among these `RandomForest` performed better and applied hyperparameter tuning onto it so that it gave the accuracy of 89% on the validation set.\n",
    "\n",
    "**Possible Future Work:**\n",
    "\n",
    "- Performing better feature engineering.\n",
    "- Tuning the Hyperparameter.\n",
    "- performing cross-validation like k_fold.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "s96XJJDLTuJ-",
    "oLIApM9TT19f",
    "IMYkb8ffUCf0",
    "LwwHORGYUcqE",
    "sPsaG1qyUugH",
    "JlS3W114U2aR",
    "nMJLwUgNVBpD"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
